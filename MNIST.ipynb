{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kuldeep725/AI/blob/master/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL7wTr-wZK7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import losses, optimizers\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from keras import backend as K\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64f7Z3J78Pho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa-2wjZnZV3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "68631997-57bd-4211-b91b-7de0988e4e2b"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "image_vector_size = x_train.shape[1]*x_train.shape[2]\n",
        "X_tot = x_train.reshape(x_train.shape[0], image_vector_size)\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqYsLqDseefy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "60710a29-b4a0-40fa-8243-0fc91f94ad21"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.083333, random_state=42)\n",
        "x_train.shape, y_train.shape, x_val.shape, y_val.shape"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((55000, 28, 28), (55000,), (5000, 28, 28), (5000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-EAd17eOTRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Flatten the images\n",
        "x_train = x_train.reshape(x_train.shape[0], image_vector_size)\n",
        "x_val = x_val.reshape(x_val.shape[0], image_vector_size)\n",
        "x_test = x_test.reshape(x_test.shape[0], image_vector_size)\n",
        "\n",
        "# Convert to \"one-hot\" vectors using the to_categorical function\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rUiFFlPfNL_",
        "colab_type": "text"
      },
      "source": [
        "### (c) Classify the dataset using a feed-forward neural network. Vary the hyperparameters as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaAebdIPnJ7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(layer_sizes, activation='sigmoid') :\n",
        "  model = Sequential()\n",
        "  input_shape = (image_vector_size,)\n",
        "  model.add(Dense(layer_sizes[0], input_shape=input_shape, activation='sigmoid'))\n",
        "  for size in layer_sizes[1:] :\n",
        "    model.add(Dense(size, activation=activation))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  return model\n",
        "\n",
        "def evaluate_network(model=None, batch_size=batch_size, epochs=epochs, x_train=x_train, x_val=x_val,\n",
        "                     alpha=0.1) :\n",
        "  sgd = optimizers.SGD(lr=alpha)\n",
        "  model.compile(loss=losses.categorical_crossentropy,\n",
        "            optimizer=sgd,\n",
        "            metrics=['accuracy'])\n",
        "  model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=(x_val, y_val))\n",
        "  score = model.evaluate(x_val, y_val, verbose=0)\n",
        "  return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzBdTbiO0Q6V",
        "colab_type": "text"
      },
      "source": [
        "# Part (i)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QgNWvuz0TfS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c2681319-1f86-43f4-9c99-bb78deb6ddc4"
      },
      "source": [
        "model = build_model([32])\n",
        "score = evaluate_network(model=model)\n",
        "\n",
        "print('Validation loss:', score[0])\n",
        "print('Validation accuracy:', score[1])"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.41615091037750246\n",
            "Test accuracy: 0.8778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYAo_zQxbwae",
        "colab_type": "text"
      },
      "source": [
        "# Part (ii)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U6muUyD0_Qc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "680cb2af-ff8a-4f41-b6d7-f1c0089982aa"
      },
      "source": [
        "transformer = Normalizer().fit(X_tot)\n",
        "x_train_normalized = transformer.transform(x_train)\n",
        "x_val_normalized = transformer.transform(x_val)\n",
        "\n",
        "model = build_model([32])\n",
        "score = evaluate_network(model=model, x_train=x_train_normalized, x_val=x_val_normalized)\n",
        "\n",
        "print('Normalized Validation loss:', score[0])\n",
        "print('Normalized Validation accuracy:', score[1])\n"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalized Test loss: 0.5958734323501587\n",
            "Normalized Test accuracy: 0.8448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL1YMAbrZ92x",
        "colab_type": "text"
      },
      "source": [
        "### Conclusion of Part (ii)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Since the time taken by normalized version is more and also the accuracy is lesser than the unnormalized version, we will stick \n",
        "with the unnormalized version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH9FzzM3fScB",
        "colab_type": "text"
      },
      "source": [
        "# Part (iii) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9uMgYHzfYOn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "a5793563-9e85-4fe1-e459-fef0eb58ba89"
      },
      "source": [
        "deepmodel2 = build_model([32, 32])\n",
        "deepmodel3 = build_model([32, 32, 32])\n",
        "score2 = evaluate_network(model=deepmodel2)\n",
        "score3 = evaluate_network(model=deepmodel3)\n",
        "\n",
        "print('With 2 hidden layers, Validation loss:', score2[0])\n",
        "print('with 2 hidden layers, Validation accuracy:', score2[1])\n",
        "\n",
        "print('With 3 hidden layers, Validation loss:', score3[0])\n",
        "print('with 3 hidden layers, Validation accuracy:', score3[1])"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With 2 hidden layers, Test loss: 0.4897109190940857\n",
            "with 2 hidden layers, Test accuracy: 0.8572\n",
            "With 3 hidden layers, Test loss: 0.6286976434707642\n",
            "with 3 hidden layers, Test accuracy: 0.797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhTaWXsnhuFv",
        "colab_type": "text"
      },
      "source": [
        "### Conclusion of Part (iii)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Accuracy with 3 hidden layers is much poor as compared to 1 and 2 hidden layers. Accuracy with one hidden layers and two hidden layers are comparable. But since the data is not that big, using 2 layers might cause overfitting. So, we can stick with single hidden layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnENu5jDqiyY",
        "colab_type": "text"
      },
      "source": [
        "# Part (iv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WGlpvPQql0X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "5e3d14f1-ddb6-4942-9e3a-f241ba7402bd"
      },
      "source": [
        "for alpha in [0.001, 0.0001] :\n",
        "  model = build_model([32])\n",
        "  score = evaluate_network(model=model, alpha=alpha)\n",
        "  print(\"Validation loss with alpha\", alpha, \":\", score[0])\n",
        "  print(\"Validation accuracy with alpha\", alpha, \":\", score[1])"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss with alpha 0.001 : 0.8669310432434082\n",
            "Test accuracy with alpha 0.001 : 0.8264\n",
            "Test loss with alpha 0.0001 : 1.788726180267334\n",
            "Test accuracy with alpha 0.0001 : 0.4522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ELTE8OzrYmC",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion for part (iv) \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Accuracy with learning rate 0.001 and 0.0001 is less as compared to learning rate 0.1. This is because now the learning rate\n",
        "is less, so algorithm needs more epochs to converge to the minima. So, for the current epoch value, we can stick with learning rate \n",
        "0.1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Twow92oLsPAG",
        "colab_type": "text"
      },
      "source": [
        "# Part (v)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k10jp6ApsVwg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "a62dab39-9021-4539-cc19-cca9dfe2bd5f"
      },
      "source": [
        "for layer_size in [64, 128] :\n",
        "  model = build_model([layer_size])\n",
        "  score = evaluate_network(model=model)\n",
        "  print(\"Validation loss with hidden layer size\", layer_size, \":\", score[0])\n",
        "  print(\"Validation accuracy with layer_size\", layer_size, \":\", score[1])\n",
        "  print()"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss with hidden layer size 64 : 0.3408801975250244\n",
            "Test accuracy with layer_size 64 : 0.8966\n",
            "\n",
            "Test loss with hidden layer size 128 : 0.3146684859752655\n",
            "Test accuracy with layer_size 128 : 0.9062\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTt8vUmHszPy",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion for part (v)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "There is significant increase in accuracy with increase in layer size. It means that increasing the hidden layer size is \n",
        "help the model to learn the parameters in much better way. So, we may opt to increase the hidden layer size, say 128. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0xw1eNxvO_8",
        "colab_type": "text"
      },
      "source": [
        "# Part (vi)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsT7Zm1YvWy7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "7077f155-1dda-4c60-f343-1756605f9690"
      },
      "source": [
        "lrelu = lambda x: keras.activations.relu(x, alpha=0.1)     # leaky relu\n",
        "activationToStr = {K.tanh: 'tanh', K.relu: 'relu', lrelu: 'leaky relu'}\n",
        "for activation in [K.tanh, K.relu, lrelu] :\n",
        "  model = build_model([128], activation=activation)\n",
        "  score = evaluate_network(model=model)\n",
        "  print(\"Validation loss with\", activationToStr[activation], \":\", score[0])\n",
        "  print(\"Validation accuracy with\", activationToStr[activation], \":\", score[1])\n",
        "  print()"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation loss with tanh : 0.2668101182937622\n",
            "Validation accuracy with tanh : 0.9206\n",
            "\n",
            "Validation loss with relu : 0.3048706015110016\n",
            "Validation accuracy with relu : 0.9106\n",
            "\n",
            "Validation loss with leaky relu : 0.2887902254104614\n",
            "Validation accuracy with leaky relu : 0.9184\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SjjdvR18i8F",
        "colab_type": "text"
      },
      "source": [
        "### Conclusion of part (vi)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Accuracy for ReLU, leaky ReLU and tanh activations appears to be better than sigmoid. I would choose ReLU between ReLU and tanh.\n",
        "The biggest advantage of ReLu is indeed non-saturation of its gradient, which greatly accelerates the convergence of stochastic gradient\n",
        "descent compared to the sigmoid / tanh functions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1RtH8bF-U3d",
        "colab_type": "text"
      },
      "source": [
        "# Part (vii)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8LMjBu7-WpB",
        "colab_type": "text"
      },
      "source": [
        "Among all the configurations used above, i will have opt for below configuration :\n",
        "  * Only one hidden layer with 128 hidden units\n",
        "  * Learning rate = 0.1\n",
        "  * Activation function for hidden layer = ReLU\n",
        "  * No normalization\n",
        "\n",
        "> The choice for above configuration is made by analysing the improvement obtained by choosing these configurations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEovU-TOBdfT",
        "colab_type": "text"
      },
      "source": [
        "# Part (viii)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EMteVQYCMeq",
        "colab_type": "text"
      },
      "source": [
        "Among all the models, i will choose the model with configuration of part (vii). The choice is made by analysing the \n",
        "performance of the model on validation data (by observing validation loss and validation accuracy)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND9PG-YZDlbk",
        "colab_type": "text"
      },
      "source": [
        "# Run Model on test data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfEF-8kVCpFg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6e82ae8e-4c43-425a-89d0-ccc596d3b84a"
      },
      "source": [
        "model = build_model([128], activation=K.relu)\n",
        "evaluate_network(model=model)\n",
        "score = model.evaluate(x_val, y_val, verbose=0)\n",
        "print(\"Test loss :\", score[0])\n",
        "print(\"Test accuracy :\", score[1])"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss : 0.29768350949287414\n",
            "Test accuracy : 0.9134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHcwbhacDWY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}