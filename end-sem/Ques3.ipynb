{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Rental Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "The idea is that we have state as a tuple - \n",
    "        - Number of cars in Location 1\n",
    "        - Number of cars in Location 2\n",
    "        - Number of cars in Location 3\n",
    "And we can take actions in the form of movement of cars from one location to another location over night.\n",
    "\n",
    "> For size = (10, 5, 5), it is taking overall 13s and converging in 5 iterations. Maximum Value obtained is 56.9\n",
    "\n",
    "> For size = (20, 10, 10), it is taking around 6-7 min to complete one iteration. Maximum value obtained after 1 iteration is 194.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math, itertools, time, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment :\n",
    "    def __init__(self, size, requestList, returnList, gamma, reward) :\n",
    "        self.size = size\n",
    "        self.V = np.zeros(size)\n",
    "        self.policy = np.zeros((size[0], size[1], size[2], 3))\n",
    "        self.gamma = gamma\n",
    "        self.requestList = requestList \n",
    "        self.returnList = returnList\n",
    "        self.reward = reward        \n",
    "        z = max(size[0], size[1], size[2])\n",
    "        self.P1 = np.zeros((z, z))\n",
    "        self.P2 = np.zeros((z, z))\n",
    "        self.P3 = np.zeros((z, z))\n",
    "        self.R1 = np.zeros((z, z))\n",
    "        self.R2 = np.zeros((z, z))\n",
    "        self.R3 = np.zeros((z, z))\n",
    "        \n",
    "    def poisson(self, k, lam) :\n",
    "        return ((lam**k) * np.exp(-lam))/np.math.factorial(k)\n",
    "        \n",
    "    def isValid(self, i, j, k, car1, car2, car3) :\n",
    "        if((i+car1) < 0 or (i+car1) >= self.size[0] or (j+car2) < 0 or (j+car2) >= self.size[1]\n",
    "              or (k+car3) < 0 or (k+car3) >= self.size[2]) :\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def totalActions(self, car1, car2, car3) :\n",
    "        actions = []\n",
    "        for i, j, k in itertools.product(np.arange(-5, 6), np.arange(-5, 6), np.arange(-5, 6)) :\n",
    "            if (i + j + k == 0) :\n",
    "                if((self.isValid(i, j, k, car1, car2, car3))) :\n",
    "                    actions.append([i, j, k])\n",
    "            \n",
    "        return actions\n",
    "    \n",
    "    #================Pre-Calculations of Probability and Rewards============\n",
    "    def storeAll(self) :\n",
    "        print(\"Pre-calculating Probability and Rewards....\")\n",
    "        size1 = np.arange(self.size[0])\n",
    "        size2 = np.arange(self.size[1])\n",
    "        size3 = np.arange(self.size[2])\n",
    "        for (car, nextCar) in itertools.product(size1, size1) :\n",
    "            for req, ret in itertools.product(size1, size1) :\n",
    "                if(req > car or car-req+ret != nextCar):\n",
    "                    continue    \n",
    "                self.P1[car, nextCar] += (self.poisson(req, requestList[0]) * self.poisson(ret, returnList[0]))\n",
    "                self.R1[car, nextCar] += (self.poisson(req, requestList[0]) * self.poisson(ret, returnList[0]) \n",
    "                                     * req * self.reward)\n",
    "                                     \n",
    "        for (car, nextCar) in itertools.product(size2, size2) :\n",
    "            for req, ret in itertools.product(size2, size2) :\n",
    "                if(req > car or car-req+ret != nextCar):\n",
    "                    continue    \n",
    "                self.P2[car, nextCar] += (self.poisson(req, requestList[1]) * self.poisson(ret, returnList[1]))\n",
    "                self.R2[car, nextCar] += (self.poisson(req, requestList[1]) * self.poisson(ret, returnList[1]) \n",
    "                                     * req * self.reward)\n",
    "                                    \n",
    "        for (car, nextCar) in itertools.product(size3, size3) :\n",
    "            for req, ret in itertools.product(size3, size3) :\n",
    "                if(req > car or car-req+ret != nextCar):\n",
    "                    continue    \n",
    "                self.P3[car, nextCar] += (self.poisson(req, requestList[2]) * self.poisson(ret, returnList[2]))\n",
    "                self.R3[car, nextCar] += (self.poisson(req, requestList[2]) * self.poisson(ret, returnList[2]) \n",
    "                                     * req * self.reward)\n",
    "        print(\"Pre-calculation done ...\")\n",
    "                \n",
    "    def ValueIteration(self) :\n",
    "        \n",
    "        iter = 0\n",
    "        while(iter < 10) :\n",
    "            iter += 1\n",
    "            print(\"======= iter \", iter, \" ========== \")\n",
    "            i = 0\n",
    "            delta = 0   \n",
    "            for car1, car2, car3 in itertools.product(np.arange(self.size[0]), np.arange(self.size[1]), np.arange(self.size[2])) :\n",
    "                i += 1\n",
    "                prevCar1, prevCar2, prevCar3 = car1, car2, car3\n",
    "                bestAction = None\n",
    "                actions = self.totalActions(car1, car2, car3)\n",
    "                maxReward = 0\n",
    "\n",
    "                for action in actions :\n",
    "                    car1 = prevCar1 + action[0]\n",
    "                    car2 = prevCar2 + action[1]\n",
    "                    car3 = prevCar3 + action[2]\n",
    "                    reward = abs(action[0]) * -2     # cost of 2 for Location 1\n",
    "                    \n",
    "                    for nextCar1, nextCar2, nextCar3 in itertools.product(np.arange(self.size[0]), np.arange(self.size[1]), np.arange(self.size[2])) :\n",
    "                                     \n",
    "                        P_car1 = self.P1[car1, nextCar1]\n",
    "                        P_car2 = self.P2[car2, nextCar2]\n",
    "                        P_car3 = self.P3[car3, nextCar3]\n",
    "                                     \n",
    "                        R_car1 = self.R1[car1, nextCar1]\n",
    "                        R_car2 = self.R2[car2, nextCar2]\n",
    "                        R_car3 = self.R3[car3, nextCar3]     \n",
    "                        \n",
    "                        immReward = (P_car1*P_car2*R_car3)+(P_car1*R_car2*P_car3)+(R_car1*P_car2* P_car3)\n",
    "                        reward += immReward + (P_car1*P_car2*P_car3 * self.gamma * self.V[nextCar1,nextCar2, nextCar3])\n",
    "                    \n",
    "                    if(reward > maxReward) :\n",
    "                        maxReward = reward\n",
    "                        bestAction = action\n",
    "                        \n",
    "                prevVal = self.V[prevCar1, prevCar2, prevCar3]\n",
    "                self.V[prevCar1, prevCar2, prevCar3] = maxReward\n",
    "                delta = max(delta, abs(maxReward - prevVal))\n",
    "                self.policy[prevCar1, prevCar2, prevCar3] = np.array(bestAction)\n",
    "                if(i % 100 == 0) :\n",
    "                    print(\"i = \", i)\n",
    "                    print(\"State : \", (prevCar1, prevCar2, prevCar3), \"V = \", self.V[prevCar1, prevCar2, prevCar3])\n",
    "                    print(\"Max-reward : \", np.max(self.V))\n",
    "                    print(\"delta : \", delta)\n",
    "                    print(\"policy = \", self.policy[prevCar1, prevCar2, prevCar3])\n",
    "                \n",
    "            if(delta < 0.1) :\n",
    "                print(\"\\n========= Value Iteration Converged =========\")\n",
    "                print(\"TOTAL ITERATIONS : \", iter)\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-calculating Probability and Rewards....\n",
      "Pre-calculation done ...\n",
      "======= iter  1  ========== \n",
      "i =  100\n",
      "State :  (0, 9, 9) V =  49.64041637722675\n",
      "Max-reward :  49.8771034377289\n",
      "delta :  49.8771034377289\n",
      "policy =  [ 5. -2. -3.]\n",
      "i =  200\n",
      "State :  (1, 9, 9) V =  54.88692203419342\n",
      "Max-reward :  55.116566162667965\n",
      "delta :  55.116566162667965\n",
      "policy =  [ 5. -2. -3.]\n",
      "i =  300\n",
      "State :  (2, 9, 9) V =  58.08253374958155\n",
      "Max-reward :  58.33270417043922\n",
      "delta :  58.33270417043922\n",
      "policy =  [ 4. -2. -2.]\n",
      "i =  400\n",
      "State :  (3, 9, 9) V =  61.291793483435825\n",
      "Max-reward :  63.62533483090205\n",
      "delta :  63.62533483090205\n",
      "policy =  [ 4. -2. -2.]\n",
      "i =  500\n",
      "State :  (4, 9, 9) V =  67.07261139246069\n",
      "Max-reward :  73.80044725416238\n",
      "delta :  73.80044725416238\n",
      "policy =  [ 2. -1. -1.]\n",
      "i =  600\n",
      "State :  (5, 9, 9) V =  71.9083572671826\n",
      "Max-reward :  86.71913502076319\n",
      "delta :  86.71913502076319\n",
      "policy =  [ 2. -1. -1.]\n",
      "i =  700\n",
      "State :  (6, 9, 9) V =  75.32464035578926\n",
      "Max-reward :  98.5625933974854\n",
      "delta :  98.5625933974854\n",
      "policy =  [ 1.  0. -1.]\n",
      "i =  800\n",
      "State :  (7, 9, 9) V =  79.04941233320326\n",
      "Max-reward :  109.66872613125173\n",
      "delta :  109.66872613125173\n",
      "policy =  [ 1.  0. -1.]\n",
      "i =  900\n",
      "State :  (8, 9, 9) V =  81.88016954672193\n",
      "Max-reward :  119.45266962695553\n",
      "delta :  119.45266962695553\n",
      "policy =  [ 1.  0. -1.]\n",
      "i =  1000\n",
      "State :  (9, 9, 9) V =  84.65547690434697\n",
      "Max-reward :  129.5002022072248\n",
      "delta :  129.5002022072248\n",
      "policy =  [0. 0. 0.]\n",
      "i =  1100\n",
      "State :  (10, 9, 9) V =  86.96871632978828\n",
      "Max-reward :  138.62226447137766\n",
      "delta :  138.62226447137766\n",
      "policy =  [0. 0. 0.]\n",
      "i =  1200\n",
      "State :  (11, 9, 9) V =  88.91275085103968\n",
      "Max-reward :  146.52081784816787\n",
      "delta :  146.52081784816787\n",
      "policy =  [0. 0. 0.]\n",
      "i =  1300\n",
      "State :  (12, 9, 9) V =  90.55558797757482\n",
      "Max-reward :  154.08965072217907\n",
      "delta :  154.08965072217907\n",
      "policy =  [0. 0. 0.]\n",
      "i =  1400\n",
      "State :  (13, 9, 9) V =  91.89626765034146\n",
      "Max-reward :  161.56838665814334\n",
      "delta :  161.56838665814334\n",
      "policy =  [0. 0. 0.]\n",
      "i =  1500\n",
      "State :  (14, 9, 9) V =  92.8380829876116\n",
      "Max-reward :  168.49802351042777\n",
      "delta :  168.49802351042777\n",
      "policy =  [0. 0. 0.]\n",
      "i =  1600\n",
      "State :  (15, 9, 9) V =  93.12595948304453\n",
      "Max-reward :  175.20958198088766\n",
      "delta :  175.20958198088766\n",
      "policy =  [0. 0. 0.]\n",
      "i =  1700\n",
      "State :  (16, 9, 9) V =  92.28922104118446\n",
      "Max-reward :  181.19546718055696\n",
      "delta :  181.19546718055696\n",
      "policy =  [0. 0. 0.]\n",
      "i =  1800\n",
      "State :  (17, 9, 9) V =  89.67664964321975\n",
      "Max-reward :  186.31086792630902\n",
      "delta :  186.31086792630902\n",
      "policy =  [0. 0. 0.]\n",
      "i =  1900\n",
      "State :  (18, 9, 9) V =  84.70397509311442\n",
      "Max-reward :  190.2397606695682\n",
      "delta :  190.2397606695682\n",
      "policy =  [0. 0. 0.]\n",
      "i =  2000\n",
      "State :  (19, 9, 9) V =  77.27622450842932\n",
      "Max-reward :  194.2005223738358\n",
      "delta :  194.2005223738358\n",
      "policy =  [0. 0. 0.]\n",
      "======= iter  2  ========== \n",
      "i =  100\n",
      "State :  (0, 9, 9) V =  113.43900616855636\n",
      "Max-reward :  194.2005223738358\n",
      "delta :  63.79858979132961\n",
      "policy =  [ 5. -2. -3.]\n",
      "i =  200\n",
      "State :  (1, 9, 9) V =  129.7116864894728\n",
      "Max-reward :  194.2005223738358\n",
      "delta :  74.8247644552794\n",
      "policy =  [ 5. -2. -3.]\n",
      "i =  300\n",
      "State :  (2, 9, 9) V =  142.3645701976716\n",
      "Max-reward :  194.2005223738358\n",
      "delta :  84.28203644809005\n",
      "policy =  [ 5. -2. -3.]\n",
      "i =  400\n",
      "State :  (3, 9, 9) V =  152.76198555183362\n",
      "Max-reward :  194.2005223738358\n",
      "delta :  91.4701920683978\n",
      "policy =  [ 5. -2. -3.]\n",
      "i =  500\n",
      "State :  (4, 9, 9) V =  161.7264626736273\n",
      "Max-reward :  194.2005223738358\n",
      "delta :  94.65385128116662\n",
      "policy =  [ 5. -2. -3.]\n",
      "i =  600\n",
      "State :  (5, 9, 9) V =  169.66401896261917\n",
      "Max-reward :  194.2005223738358\n",
      "delta :  97.75566169543657\n",
      "policy =  [ 5. -2. -3.]\n",
      "i =  700\n",
      "State :  (6, 9, 9) V =  176.77274704214148\n",
      "Max-reward :  194.2005223738358\n",
      "delta :  101.44810668635222\n",
      "policy =  [ 5. -2. -3.]\n",
      "i =  800\n",
      "State :  (7, 9, 9) V =  183.00384964143183\n",
      "Max-reward :  194.2005223738358\n",
      "delta :  103.95443730822856\n",
      "policy =  [ 5. -2. -3.]\n",
      "i =  900\n",
      "State :  (8, 9, 9) V =  188.12147577286976\n",
      "Max-reward :  194.2005223738358\n",
      "delta :  106.24130622614783\n",
      "policy =  [ 5. -2. -3.]\n",
      "i =  1000\n",
      "State :  (9, 9, 9) V =  191.5062705521113\n",
      "Max-reward :  200.73642863701704\n",
      "delta :  106.85079364776432\n",
      "policy =  [ 5. -2. -3.]\n",
      "i =  1100\n",
      "State :  (10, 9, 9) V =  191.87976877708678\n",
      "Max-reward :  209.378044112479\n",
      "delta :  106.85079364776432\n",
      "policy =  [ 5. -2. -3.]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-70f92b8e6250>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0menvObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoreAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0menvObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValueIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total Time taken : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\"s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-2a2ac7191817>\u001b[0m in \u001b[0;36mValueIteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m                         \u001b[0mP_car3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcar3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextCar3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                         \u001b[0mR_car1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcar1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextCar1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                         \u001b[0mR_car2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcar2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextCar2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                         \u001b[0mR_car3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcar3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextCar3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "size = [20, 10, 10]\n",
    "# size = [10, 5, 5]\n",
    "requestList = [3, 2, 2]\n",
    "returnList = [3, 1, 1]\n",
    "gamma = 0.9\n",
    "reward = 10\n",
    "envObj = Environment(size, requestList, returnList, gamma, reward)\n",
    "\n",
    "a = time.time()\n",
    "envObj.storeAll()\n",
    "envObj.ValueIteration()\n",
    "b = time.time()\n",
    "print(\"Total Time taken : \", int((b-a)) ,\"s\")\n",
    "\n",
    "np.savetxt(\"value.txt\", np.ravel(envObj.V).reshape(50, 5), fmt = \"%5.2f\", header = 'Values')\n",
    "np.savetxt(\"policy.txt\", np.ravel(envObj.policy).reshape(250, 3), fmt = \"%d\", header = \"Policy\")\n",
    "print(\"value.txt Saved\")\n",
    "print(\"policy.txt Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209.378044112479"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(envObj.V)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
